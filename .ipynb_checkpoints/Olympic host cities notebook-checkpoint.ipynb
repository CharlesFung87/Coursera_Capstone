{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olympic host cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is part of capstone project for Coursera course “Applied Data Science Capstone”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Created by: Charles Fung Nov, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import requests # library to handle requests\n",
    "\n",
    "# uncomment the line to install beautifulsoup4\n",
    "#!conda install -c conda-forge beautifulsoup4 --yes\n",
    "from bs4 import BeautifulSoup # library to parse html\n",
    "\n",
    "import numpy as np # library to handle data in a vectorized manner\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import json # library to handle JSON files\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# uncomment this line if you need to install\n",
    "#!conda install -c conda-forge geopy --yes\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "# import k-means from clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# uncomment this line if you haven't installed folium\n",
    "#!conda install -c conda-forge folium=0.5.0 --yes \n",
    "import folium # map rendering library\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Foursquare Credentials and Version\n",
    "CLIENT_ID = 'QNVE1AVGXR2RR53OS2RT1HOR4BPF2GYXMQLQCGLY1PCEYDA0' # your Foursquare ID\n",
    "CLIENT_SECRET = '1MHJEVX2I3U142QW5LCBBYCNVHBCXA2NOLFTRGWPE51ZROPP' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "\n",
    "LIMIT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view categories at https://developer.foursquare.com/docs/resources/categories\n",
    "# get categories by venues API\n",
    "categories_url = 'https://api.foursquare.com/v2/venues/categories?&client_id={}&client_secret={}&v={}'.format(           \n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION\n",
    "            )\n",
    "categories_response = requests.get(categories_url).json()['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recursively collect category names\n",
    "def flatten_categories(json):\n",
    "    cats = []\n",
    "    cat_json = json['categories']    \n",
    "    if len(cat_json):\n",
    "        for c in cat_json:\n",
    "            cats.append(c['name'])\n",
    "            cats.extend(flatten_categories(c))\n",
    "    return cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories = flatten_categories(categories_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 937 venue categories.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} venue categories.\".format(len(all_categories)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get olympic host cities¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv file from https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results#athlete_events.csv\n",
    "events = pd.read_csv(\"athlete_events.csv\")\n",
    "evt_summer = events[events['Season'] == \"Summer\"][[\"Year\", \"City\", \"ID\"]]\n",
    "evt_city = evt_summer.groupby([\"Year\", \"City\"]).count().reset_index().drop(\"ID\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame({'Year': [2020, 2024, 2028], 'City': ['Tokyo', 'Paris', 'Los Angeles']})\n",
    "evt_city = evt_city.append(x, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_cities = pd.DataFrame(evt_city.drop_duplicates(subset=['City'], keep='last'))\n",
    "# Stockholm was co-host in 1956 for Equestrian events only\n",
    "host_cities = host_cities[((host_cities['Year'] > 1945) & (host_cities['City'] != \"Stockholm\"))]\n",
    "host_cities = host_cities[host_cities['Year'] != 1964]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The past host cities are: Helsinki, Melbourne, Roma, Mexico City, Munich, Montreal, Moskva, Seoul, Barcelona, Atlanta, Sydney, Athina, Beijing, London, Rio de Janeiro, Tokyo, Paris, Los Angeles\n"
     ]
    }
   ],
   "source": [
    "print(\"The past host cities are: {}\".format(', '.join(host_cities['City'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get coordinates and country codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"my-coursera-application\")\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "country_codes = []\n",
    "for c in host_cities.loc[:,'City']:\n",
    "    location = geolocator.geocode(c, addressdetails=True)\n",
    "    latitudes.append(location.latitude)\n",
    "    longitudes.append(location.longitude)\n",
    "    country_codes.append(location.raw['address']['country_code'])\n",
    "host_cities['Lat'] = latitudes\n",
    "host_cities['Lng'] = longitudes\n",
    "host_cities['Cnty'] = country_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_cities['Host'] = 1\n",
    "# Replace city names to be consistent with American spelling so they compare \n",
    "#  correctly with best city list. There is also Athens in the US!\n",
    "# Do this after geopy calls to ensure we get the correct countries.\n",
    "host_cities.replace({\"Moskva\": \"Moscow\", \"Athina\": \"Athens\", \"Roma\": \"Rome\"}, inplace=True)\n",
    "host_cities.set_index('City', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get popular venues for host cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=10000, limit= 100):\n",
    "    \"\"\"\n",
    "    Retrieve venues near to coordinates using foursquare API\n",
    "    \n",
    "    Arguments:\n",
    "    names - names of city, list of string\n",
    "    latitudes - latitudes of city, list of float\n",
    "    longitudes - longitudes of city, list of float\n",
    "    radius - search distance in m, int\n",
    "    limit - serach result limit, int\n",
    "    \n",
    "    Return:\n",
    "    DataFrame containing city and venue information: latitudes, longitudes, categories\n",
    "    \"\"\"\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            limit)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name,\n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['City', 'Venue Category']\n",
    "    \n",
    "    return nearby_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get venues for all host cities\n",
    "city_venues = getNearbyVenues(host_cities.index, host_cities['Lat'], host_cities['Lng'])\n",
    "print(\"Call completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "city_venues['Count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped = city_venues.groupby(['City','Venue Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv = pd.pivot_table(city_venues.groupby(['City', 'Venue Category']).count(), values=\"Count\", index=\"City\",\n",
    "                   columns = \"Venue Category\", fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_grouped = city_venues.groupby('Venue Category').count().sort_values('City', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(category_grouped.index[0:15])\n",
    "print(\"The top 15 common categories are: {}\". format(', '.join(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_host = pv[features].join(host_cities, on='City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_host.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_host.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_host.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Host cities clustering by KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "venue_onehot = pd.get_dummies(city_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add city column back to dataframe\n",
    "venue_onehot['City'] = city_venues['City']\n",
    "\n",
    "# move city column to the first column\n",
    "# the new column does not always append to the end, so figure out where it is and concatenate accordingly\n",
    "idx = venue_onehot.columns.tolist().index('City')\n",
    "fixed_columns = ([venue_onehot.columns[idx]] + list(venue_onehot.columns[0:idx]) + list(venue_onehot.columns[idx+1:]))\n",
    "venue_onehot = venue_onehot[fixed_columns]\n",
    "\n",
    "venue_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_grouped = venue_onehot.groupby('City').mean().reset_index()\n",
    "venue_grouped.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 5\n",
    "\n",
    "for city in venue_grouped['City']:\n",
    "    print(\"----\"+city+\"----\")\n",
    "    temp = venue_grouped[venue_grouped['City'] == city].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_grouped_clustering = venue_grouped.drop('City', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(init = \"k-means++\", n_clusters = 3, n_init = 12, random_state=4)\n",
    "k_means.fit(venue_grouped_clustering)\n",
    "k_means_labels = k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "host_clustered = pd.DataFrame(venue_grouped['City']).set_index('City')\n",
    "\n",
    "# add clustering labels\n",
    "host_clustered['Cluster'] = k_means_labels\n",
    "city_data = host_cities[[\"Year\", \"Cnty\", \"Lat\", \"Lng\"]]\n",
    "host_clustered = city_data.join(host_clustered, how=\"inner\", on='City')\n",
    "host_clustered\n",
    "#venue_merged # check the last columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    m = host_clustered[host_clustered['Cluster'] == i].index\n",
    "    print(\"Cluster {} cities are: {}\".format(i, ', '.join(m)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_clustered[['Year', 'Cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "people = host_clustered.index\n",
    "y_pos = list(host_clustered.Year - 1945)\n",
    "performance = 25\n",
    "c_map = {0:\"red\", 1:\"green\", 2:\"blue\"}\n",
    "colors = [c_map[cl] for cl in host_clustered['Cluster']]\n",
    "\n",
    "\n",
    "ax.barh(y_pos, performance, align='center',\n",
    "        color=colors)\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(people)\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_title('host cities by cluster')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_clustered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_grouped_cnt = venue_onehot.groupby('City').sum().reset_index()\n",
    "venue_grouped_cnt.set_index('City', drop=True, inplace=True)\n",
    "venue_grouped_cnt['Cluster'] = venue_merged['Cluster']\n",
    "venue_grouped_cnt.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "venue_grouped_cluster_cnt = venue_grouped_cnt.groupby('Cluster').mean().reset_index()\n",
    "venue_grouped_cluster_cnt.set_index('Cluster', drop=True, inplace=True)\n",
    "venue_grouped_cluster_cnt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_grouped_cluster_cnt[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_grouped_cluster_cnt[features].plot(kind='bar', stacked=True, figsize=(12, 8))\n",
    "plt.title(\"Mean of venue categories by host city cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 0 represents the 'older' host cities, within 30 years after WWII \n",
    "\n",
    "Cluster 1 represents the 'modern' host cities\n",
    "\n",
    "Cluster 2 includes Beijing only and is an outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosts = list(host_clustered[host_clustered['Cluster'] == 1].index)\n",
    "hosts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get non-host cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.bestcities.org/rankings/worlds-best-cities/'\n",
    "response = requests.get(url).content\n",
    "soup = BeautifulSoup(response, 'html.parser') # create the soup, using basic html parser\n",
    "all_city_names = soup.find_all('div', class_='rankings-cities-detail') # access the city names by its class_\n",
    "all_city_names = [n.text[9:].strip('\\n\\t .') for n in all_city_names]\n",
    "city_names = all_city_names[0:20]  # use only 20 of them to balance the number of past host cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_host_names = sorted(set(all_city_names[0:20]).difference(set(host_cities.index)))\n",
    "print(\"There are {} non-host cities.\".format(len(non_host_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The non-host cities are: {}\".format(', '.join(non_host_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_host_cities = pd.DataFrame(non_host_names, columns = ['City'])\n",
    "non_host_cities['Host'] = 0  # these were not host cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coordinates of cities\n",
    "geolocator = Nominatim(user_agent=\"my-coursera-application\")\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "for c in non_host_cities.City:\n",
    "    location = geolocator.geocode(c)\n",
    "    latitudes.append(location.latitude)\n",
    "    longitudes.append(location.longitude)\n",
    "non_host_cities['Lat'] = latitudes\n",
    "non_host_cities['Lng'] = longitudes\n",
    "non_host_cities.set_index('City', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_host_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get venues for non-host cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get venues for all cities neighborhoods\n",
    "non_host_city_venues = getNearbyVenues(non_host_cities.index, non_host_cities['Lat'], non_host_cities['Lng'])\n",
    "print(\"Call completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_host_city_venues['Count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_host_pv = pd.pivot_table(non_host_city_venues.groupby(['City', 'Venue Category']).count(), values=\"Count\", index=\"City\",\n",
    "                   columns = \"Venue Category\", fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_host_pv['Total'] = non_host_pv.sum(axis=1)  # add a Total column to inspect how many venues each city has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_host_pv['Total'].sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "non_host_venue_onehot = pd.get_dummies(non_host_city_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add city column back to dataframe\n",
    "non_host_venue_onehot['City'] = non_host_city_venues['City']\n",
    "\n",
    "# move city column to the first column\n",
    "# the new column does not always append to the end, so figure out where it is and concatenate accordingly\n",
    "idx = non_host_venue_onehot.columns.tolist().index('City')\n",
    "fixed_columns = ([non_host_venue_onehot.columns[idx]] + list(non_host_venue_onehot.columns[0:idx]) + list(non_host_venue_onehot.columns[idx+1:]))\n",
    "non_host_venue_onehot = non_host_venue_onehot[fixed_columns]\n",
    "\n",
    "non_host_venue_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_host_venue_grouped = non_host_venue_onehot.groupby('City').mean().reset_index()\n",
    "non_host_venue_grouped.set_index('City', drop=True, inplace=True)\n",
    "non_host_venue_grouped['Host'] = 0\n",
    "non_host_venue_grouped.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_venue_grouped = (venue_grouped[venue_grouped.City.isin(hosts)]).copy()\n",
    "host_venue_grouped['Host'] = 1\n",
    "host_venue_grouped.set_index('City', drop=True, inplace=True)\n",
    "host_venue_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_venue_grouped = host_venue_grouped.append(non_host_venue_grouped, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_venue_grouped.fillna(0, inplace=True)  # in case non-host city missing a venue category\n",
    "all_venue_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_venue_grouped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features + ['Host']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_venue_grouped_sel = all_venue_grouped[features + ['Host']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_venue_grouped_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_venue_grouped_sel_grouped = all_venue_grouped_sel.groupby(['Host']).mean()\n",
    "all_venue_grouped_sel_grouped.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_venue_grouped_sel_grouped.plot(kind='bar', stacked=True, width=0.2, figsize=(12, 8))\n",
    "plt.xticks([0, 1], ['Non-host', 'Host'])\n",
    "plt.xlabel(\"\")\n",
    "plt.title(\"Top 15 venue categories in non-host and host cities\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_host_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cities = pd.concat([host_cities[['Host', 'Lat', 'Lng']], non_host_cities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map of world using latitude and longitude values\n",
    "lat_c = all_cities['Lat'][2]  # lat of city 1\n",
    "lng_c = all_cities['Lng'][2]\n",
    "colors = ['red' if h == 1 else 'blue' for h in all_cities['Host']]\n",
    "\n",
    "map_world = folium.Map(location=[lat_c, lng_c], zoom_start=2)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, city, c in zip(all_cities['Lat'], all_cities['Lng'], all_cities.index, colors):\n",
    "    label = '{}'.format(city)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=c,\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_world)  \n",
    "\n",
    "map_world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_venue_grouped_sel[all_venue_grouped_sel.columns[0:-1]]\n",
    "y = all_venue_grouped_sel['Host']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X.values, y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
    "m_tree.fit(x_train,y_train)\n",
    "predTree = m_tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, m_tree.predict(x_train)))\n",
    "print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, predTree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, predTree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, predTree, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = m_tree.predict_proba(X)\n",
    "city_pred = all_venue_grouped_sel[['Host']].copy()\n",
    "pred = pd.DataFrame(pred_prob, columns = ['F', 'T'], index = all_venue_grouped_sel.index)\n",
    "city_pred['pred'] = pred['T']\n",
    "city_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### decision tree visual\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals.six import StringIO\n",
    "import pydotplus\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn import tree\n",
    "%matplotlib inline \n",
    "\n",
    "# drugTree is a model DecisionTreeClassifier\n",
    "### write image to disk and read/show\n",
    "dot_data = StringIO()\n",
    "filename = \"citytree.png\"\n",
    "featureNames = features # column names\n",
    "targetNames = ['0', '1'] #np.unique(y_train)\n",
    "out=tree.export_graphviz(m_tree,feature_names=featureNames, out_file=dot_data, class_names=targetNames, filled=True, special_characters=True, rotate=False)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "graph.write_png(filename)\n",
    "img = mpimg.imread(filename)\n",
    "plt.figure(figsize=(100, 200))\n",
    "plt.imshow(img,interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_venue_grouped_sel[all_venue_grouped_sel.columns[0:-1]]\n",
    "y = all_venue_grouped_sel['Host']\n",
    "X = preprocessing.StandardScaler().fit_transform(X.astype(float))  #make sure values are floats\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C=0.1, solver='liblinear').fit(x_train,y_train)\n",
    "yhat = LR.predict(x_test)\n",
    "yhat_prob = LR.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "jaccard_similarity_score(y_test, yhat)  # 1.0 is complete match, 0.0 is complete mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, yhat, labels=[1,0]))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, yhat, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = LR.predict_proba(X)\n",
    "city_pred = all_venue_grouped_sel[['Host']].copy()\n",
    "pred = pd.DataFrame(pred_prob, columns = ['F', 'T'], index = all_venue_grouped_sel.index)\n",
    "city_pred['pred'] = pred['T']\n",
    "city_pred.sort_values('pred', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
